{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a1048596/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)5dded/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 1.07MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 2.21MB/s]\n",
      "Downloading (…)4d81d5dded/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 35.4MB/s]\n",
      "Downloading (…)81d5dded/config.json: 100%|██████████| 573/573 [00:00<00:00, 2.37MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 586kB/s]\n",
      "Downloading (…)ded/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 15.8MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 134M/134M [00:06<00:00, 21.0MB/s] \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 340kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 737kB/s]\n",
      "Downloading (…)5dded/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 9.45MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 352/352 [00:00<00:00, 1.15MB/s]\n",
      "Downloading (…)dded/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 28.7MB/s]\n",
      "Downloading (…)4d81d5dded/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 37.2MB/s]\n",
      "Downloading (…)1d5dded/modules.json: 100%|██████████| 349/349 [00:00<00:00, 1.10MB/s]\n"
     ]
    }
   ],
   "source": [
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "# model = SentenceTransformer('all-distilroberta-v1')\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt = pd.read_csv('generated_text_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = chatgpt.query('race == \"African\" and gender == \"man\"')\n",
    "bw = chatgpt.query('race == \"African\" and gender == \"woman\"')\n",
    "\n",
    "am = chatgpt.query('race == \"Asian\" and gender == \"man\"')\n",
    "aw = chatgpt.query('race == \"Asian\" and gender == \"woman\"')\n",
    "\n",
    "hm = chatgpt.query('race == \"Hispanic\" and gender == \"man\"')\n",
    "hw = chatgpt.query('race == \"Hispanic\" and gender == \"woman\"')\n",
    "\n",
    "wm = chatgpt.query('race == \"White\" and gender == \"man\"')\n",
    "ww = chatgpt.query('race == \"White\" and gender == \"woman\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_texts_by_format = [bm.groupby('format').get_group(x).text for x in chatgpt.format.unique()]\n",
    "bw_texts_by_format = [bw.groupby('format').get_group(x).text for x in chatgpt.format.unique()]\n",
    "\n",
    "am_texts_by_format = [am.groupby('format').get_group(x).text for x in chatgpt.format.unique()]\n",
    "aw_texts_by_format = [aw.groupby('format').get_group(x).text for x in chatgpt.format.unique()]\n",
    "\n",
    "hm_texts_by_format = [hm.groupby('format').get_group(x).text for x in chatgpt.format.unique()]\n",
    "hw_texts_by_format = [hw.groupby('format').get_group(x).text for x in chatgpt.format.unique()]\n",
    "\n",
    "wm_texts_by_format = [wm.groupby('format').get_group(x).text for x in chatgpt.format.unique()]\n",
    "ww_texts_by_format = [ww.groupby('format').get_group(x).text for x in chatgpt.format.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_cosines(list_of_text):\n",
    "    embedding = model.encode(list_of_text)\n",
    "    cosines = util.cos_sim(embedding, embedding)\n",
    "    return(cosines[np.triu_indices(len(list_of_text),1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_cosines = [return_cosines(list(x)) for x in bm_texts_by_format]\n",
    "bw_cosines = [return_cosines(list(x)) for x in bw_texts_by_format]\n",
    "\n",
    "am_cosines = [return_cosines(list(x)) for x in am_texts_by_format]\n",
    "aw_cosines = [return_cosines(list(x)) for x in aw_texts_by_format]\n",
    "\n",
    "hm_cosines = [return_cosines(list(x)) for x in hm_texts_by_format]\n",
    "hw_cosines = [return_cosines(list(x)) for x in hw_texts_by_format]\n",
    "\n",
    "wm_cosines = [return_cosines(list(x)) for x in wm_texts_by_format]\n",
    "ww_cosines = [return_cosines(list(x)) for x in ww_texts_by_format]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmc = np.array([x for row in bm_cosines for x in row])\n",
    "bwc = np.array([x for row in bw_cosines for x in row])\n",
    "\n",
    "amc = np.array([x for row in am_cosines for x in row])\n",
    "awc = np.array([x for row in aw_cosines for x in row])\n",
    "\n",
    "hmc = np.array([x for row in hm_cosines for x in row])\n",
    "hwc = np.array([x for row in hw_cosines for x in row])\n",
    "\n",
    "wmc = np.array([x for row in wm_cosines for x in row])\n",
    "wwc = np.array([x for row in ww_cosines for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_length = len(bmc)\n",
    "format_length = len(bm_cosines[0])\n",
    "\n",
    "race_list = np.repeat(['African Americans', 'Asian Americans', 'Hispanic Americans', 'White Americans'],  group_length * 2)\n",
    "gender_list = np.tile(np.repeat([\"Man\", \"Woman\"], group_length), 4)\n",
    "format_list = np.tile(np.repeat(chatgpt.format.unique(), format_length), 8)\n",
    "cosine_list = np.concatenate([bmc, bwc, amc, awc, hmc, hwc, wmc, wwc])\n",
    "\n",
    "cosine_df = pd.DataFrame(list(zip(race_list, gender_list, format_list, cosine_list)), columns = ['race', 'gender', 'format', 'cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "# path = 'all-mpnet-base-v2.feather'\n",
    "# path = 'all_distilroberta_v1.feather'\n",
    "path = 'all-MiniLM-L12-v2.feather'\n",
    "feather.write_dataframe(cosine_df, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
